{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cd27024",
   "metadata": {},
   "source": [
    "# LLM Tool Calling to ReAct Agent Tutorial\n",
    "\n",
    "This tutorial progressively builds from basic LLM tool calling concepts to implementing a full ReAct agent.\n",
    "\n",
    "## What we'll cover:\n",
    "### Part 1\n",
    "1. **Basic Tool Calling**: Understanding the fundamentals\n",
    "2. **LangChain Integration**: Using LangChain for tool calling\n",
    "### Part 2\n",
    "3. **LangGraph Integration**: Building more complex workflows\n",
    "4. **ReAct Agent**: Implementing a complete ReAct (Reasoning and Acting) agent\n",
    "\n",
    "Let's start with the basics and work our way up!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054b24fc",
   "metadata": {},
   "source": [
    "## 1. Basic Tool Calling Fundamentals\n",
    "\n",
    "Before diving into frameworks, let's understand the core concepts of tool calling with LLMs.\n",
    "\n",
    "> uv install guide at https://docs.astral.sh/uv/guides/install-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e5d8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install openai langchain langgraph langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e69bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90de8cfb",
   "metadata": {},
   "source": [
    "### Step 1.1: Define a Simple Tool\n",
    "\n",
    "Let's start with a basic calculator tool to understand the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "647eac50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 3 = 5\n",
      "10 / 2 = 5.0\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "\n",
    "def calculator(operation: str, a: float, b: float) -> Union[float, str]:\n",
    "    \"\"\"A simple calculator function\"\"\"\n",
    "    if operation == \"add\":\n",
    "        return a + b\n",
    "    elif operation == \"subtract\":\n",
    "        return a - b\n",
    "    elif operation == \"multiply\":\n",
    "        return a * b\n",
    "    elif operation == \"divide\":\n",
    "        if b != 0:\n",
    "            return a / b\n",
    "        else:\n",
    "            return \"Error: Division by zero\"\n",
    "    else:\n",
    "        return \"Error: Unsupported operation\"\n",
    "\n",
    "# Test the function\n",
    "print(f\"2 + 3 = {calculator('add', 2, 3)}\")\n",
    "print(f\"10 / 2 = {calculator('divide', 10, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247ca64e",
   "metadata": {},
   "source": [
    "### Step 1.2: Define Tool Schema for LLM\n",
    "\n",
    "The LLM needs to understand what tools are available and how to use them. We define this using a schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d489506a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool schema defined:\n",
      "{\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"calculator\",\n",
      "    \"description\": \"Perform basic arithmetic operations (add, subtract, multiply, divide)\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"operation\": {\n",
      "          \"type\": \"string\",\n",
      "          \"enum\": [\n",
      "            \"add\",\n",
      "            \"subtract\",\n",
      "            \"multiply\",\n",
      "            \"divide\"\n",
      "          ],\n",
      "          \"description\": \"The arithmetic operation to perform\"\n",
      "        },\n",
      "        \"a\": {\n",
      "          \"type\": \"number\",\n",
      "          \"description\": \"The first number\"\n",
      "        },\n",
      "        \"b\": {\n",
      "          \"type\": \"number\",\n",
      "          \"description\": \"The second number\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"operation\",\n",
      "        \"a\",\n",
      "        \"b\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Tool schema that describes our calculator to the LLM\n",
    "tool_schema = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"calculator\",\n",
    "        \"description\": \"Perform basic arithmetic operations (add, subtract, multiply, divide)\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"operation\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"add\", \"subtract\", \"multiply\", \"divide\"],\n",
    "                    \"description\": \"The arithmetic operation to perform\"\n",
    "                },\n",
    "                \"a\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"The first number\"\n",
    "                },\n",
    "                \"b\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"The second number\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"operation\", \"a\", \"b\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Tool schema defined:\")\n",
    "print(json.dumps(tool_schema, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2f8272",
   "metadata": {},
   "source": [
    "### Step 1.3: Basic Tool Calling with OpenAI\n",
    "\n",
    "Now let's see how the LLM decides to call our tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d464bc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is 25 + 17?\n",
      "\n",
      "LLM Response:\n",
      "ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_pdqNrXHJbbPac1N6zMEOTee3', function=Function(arguments='{\"operation\":\"add\",\"a\":25,\"b\":17}', name='calculator'), type='function')])\n"
     ]
    }
   ],
   "source": [
    "def call_llm_with_tools(user_message: str):\n",
    "    \"\"\"Call LLM with tool calling capability\"\"\"\n",
    "    \n",
    "    # Send message to LLM with tool available\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",  # or use \"gpt-4o-mini\" for OpenAI's latest model\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ],\n",
    "        tools=[tool_schema], # type: ignore\n",
    "        tool_choice=\"required\"  # Let the LLM decide whether to use tools\n",
    "    )\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Test with a mathematical question\n",
    "user_query = \"What is 25 + 17?\"\n",
    "print(f\"User: {user_query}\\n\")\n",
    "\n",
    "response = call_llm_with_tools(user_query)\n",
    "print(\"LLM Response:\")\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d15a30",
   "metadata": {},
   "source": [
    "### Step 1.4: Handle Tool Calls\n",
    "\n",
    "When the LLM decides to use a tool, we need to execute it and send the results back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18eae318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß LLM decided to use a tool!\n",
      "Tool: calculator\n",
      "Arguments: {'operation': 'add', 'a': 25, 'b': 17}\n",
      "Result: 42\n",
      "\n",
      "‚úÖ Final Answer: 42\n"
     ]
    }
   ],
   "source": [
    "def execute_tool_calls(response):\n",
    "    \"\"\"Execute tool calls from LLM response\"\"\"\n",
    "    \n",
    "    message = response.choices[0].message\n",
    "    \n",
    "    # Check if the LLM wants to call a tool\n",
    "    if message.tool_calls:\n",
    "        print(\"üîß LLM decided to use a tool!\")\n",
    "        \n",
    "        # Process each tool call\n",
    "        for tool_call in message.tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            \n",
    "            print(f\"Tool: {function_name}\")\n",
    "            print(f\"Arguments: {function_args}\")\n",
    "            \n",
    "            # Execute our calculator function\n",
    "            if function_name == \"calculator\":\n",
    "                result = calculator(\n",
    "                    function_args[\"operation\"],\n",
    "                    function_args[\"a\"],\n",
    "                    function_args[\"b\"]\n",
    "                )\n",
    "                print(f\"Result: {result}\")\n",
    "                return result\n",
    "    else:\n",
    "        print(\"üìù LLM responded without using tools:\")\n",
    "        print(message.content)\n",
    "        return message.content\n",
    "\n",
    "# Execute the tool call from our previous response\n",
    "result = execute_tool_calls(response)\n",
    "print(f\"\\n‚úÖ Final Answer: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9d9b52",
   "metadata": {},
   "source": [
    "### Step 1.5: Complete Tool Calling Flow\n",
    "\n",
    "Let's put it all together in a complete function that handles the full flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f08dc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ User: Calculate 15 * 8 for me\n",
      "\n",
      "ü§ñ LLM: I need to use the calculator tool...\n",
      "\n",
      "üîß Calling calculator with {'operation': 'multiply', 'a': 15, 'b': 8}\n",
      "üìä Tool result: 120\n",
      "\n",
      "ü§ñ LLM: I need to use the calculator tool...\n",
      "\n",
      "üîß Calling calculator with {'operation': 'multiply', 'a': 15, 'b': 8}\n",
      "üìä Tool result: 120\n",
      "\n",
      "ü§ñ LLM Final Response: 15 * 8 equals 120.\n",
      "\n",
      "==================================================\n",
      "\n",
      "üë§ User: What's the weather like?\n",
      "\n",
      "ü§ñ LLM Final Response: 15 * 8 equals 120.\n",
      "\n",
      "==================================================\n",
      "\n",
      "üë§ User: What's the weather like?\n",
      "\n",
      "ü§ñ LLM: I'm not able to provide real-time weather updates. If you'd like, I can help you with some other requests or tasks. Just let me know how I can assist you today!\n",
      "ü§ñ LLM: I'm not able to provide real-time weather updates. If you'd like, I can help you with some other requests or tasks. Just let me know how I can assist you today!\n"
     ]
    }
   ],
   "source": [
    "def complete_tool_calling_flow(user_message: str):\n",
    "    \"\"\"Complete flow: User message -> LLM -> Tool execution -> Final response\"\"\"\n",
    "    \n",
    "    print(f\"üë§ User: {user_message}\\n\")\n",
    "    \n",
    "    # Step 1: Send user message to LLM\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": user_message}],\n",
    "        tools=[tool_schema],  # type: ignore\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "    \n",
    "    message = response.choices[0].message\n",
    "    \n",
    "    # Step 2: Check if LLM wants to use tools\n",
    "    if message.tool_calls:\n",
    "        # Step 3: Execute tool calls\n",
    "        tool_results = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            \n",
    "            if function_name == \"calculator\":\n",
    "                result = calculator(\n",
    "                    function_args[\"operation\"],\n",
    "                    function_args[\"a\"],\n",
    "                    function_args[\"b\"]\n",
    "                )\n",
    "                tool_results.append({\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": str(result)\n",
    "                })\n",
    "        \n",
    "        # Step 4: Send tool results back to LLM for final response\n",
    "        final_response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": user_message},\n",
    "                message, # type: ignore\n",
    "                *tool_results\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        final_answer = final_response.choices[0].message.content\n",
    "        print(f\"ü§ñ LLM Final Response: {final_answer}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"ü§ñ LLM: {message.content}\")\n",
    "\n",
    "# Test the complete flow\n",
    "complete_tool_calling_flow(\"Calculate 15 * 8 for me\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "complete_tool_calling_flow(\"What's the weather like?\")  # Should not use calculator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bade7328",
   "metadata": {},
   "source": [
    "## 2. LangChain Integration\n",
    "\n",
    "Now let's see how LangChain simplifies tool calling with its built-in abstractions.\n",
    "\n",
    "> [LangChain Runnable](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d071b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea17ecb",
   "metadata": {},
   "source": [
    "### Step 2.1: Define Tools with LangChain Decorators\n",
    "\n",
    "LangChain provides a simple `@tool` decorator to define tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81833c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculator tool:\n",
      "Name: calculator_tool\n",
      "Description: Perform basic arithmetic operations (add, subtract, multiply, divide).\n",
      "\n",
      "Args:\n",
      "    operation: The operation to perform (add, subtract, multiply, divide)\n",
      "    a: First number\n",
      "    b: Second number\n",
      "\n",
      "Returns:\n",
      "    The result of the arithmetic operation\n",
      "Args schema: {'operation': {'title': 'Operation', 'type': 'string'}, 'a': {'title': 'A', 'type': 'number'}, 'b': {'title': 'B', 'type': 'number'}}\n",
      "\n",
      "Word length tool:\n",
      "Name: get_word_length\n",
      "Description: Get the length of a word.\n",
      "\n",
      "Args:\n",
      "    word: The word to count characters for\n",
      "\n",
      "Returns:\n",
      "    Number of characters in the word\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def calculator_tool(operation: str, a: float, b: float) -> Union[float, str]:\n",
    "    \"\"\"Perform basic arithmetic operations (add, subtract, multiply, divide).\n",
    "    \n",
    "    Args:\n",
    "        operation: The operation to perform (add, subtract, multiply, divide)\n",
    "        a: First number\n",
    "        b: Second number\n",
    "    \n",
    "    Returns:\n",
    "        The result of the arithmetic operation\n",
    "    \"\"\"\n",
    "    if operation == \"add\":\n",
    "        return a + b\n",
    "    elif operation == \"subtract\":\n",
    "        return a - b\n",
    "    elif operation == \"multiply\":\n",
    "        return a * b\n",
    "    elif operation == \"divide\":\n",
    "        if b != 0:\n",
    "            return a / b\n",
    "        else:\n",
    "            return \"Error: Division by zero\"\n",
    "    else:\n",
    "        return \"Error: Unsupported operation\"\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Get the length of a word.\n",
    "    \n",
    "    Args:\n",
    "        word: The word to count characters for\n",
    "    \n",
    "    Returns:\n",
    "        Number of characters in the word\n",
    "    \"\"\"\n",
    "    return len(word)\n",
    "\n",
    "# Let's see what LangChain created for us\n",
    "print(\"Calculator tool:\")\n",
    "print(f\"Name: {calculator_tool.name}\")\n",
    "print(f\"Description: {calculator_tool.description}\")\n",
    "print(f\"Args schema: {calculator_tool.args}\")\n",
    "\n",
    "print(\"\\nWord length tool:\")\n",
    "print(f\"Name: {get_word_length.name}\")\n",
    "print(f\"Description: {get_word_length.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae13f096",
   "metadata": {},
   "source": [
    "### Step 2.2: Simple Tool Calling with LangChain\n",
    "\n",
    "LangChain makes it much easier to bind tools to an LLM and handle the calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c343bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ User: What is 20 divided by 4?\n",
      "ü§ñ LLM Response type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "ü§ñ Content: \n",
      "üîß Tool calls: 1\n",
      "   - calculator_tool with args: {'operation': 'divide', 'a': 20, 'b': 4}\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "üë§ User: How many letters are in the word 'LangChain'?\n",
      "ü§ñ LLM Response type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "ü§ñ Content: \n",
      "üîß Tool calls: 1\n",
      "   - calculator_tool with args: {'operation': 'divide', 'a': 20, 'b': 4}\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "üë§ User: How many letters are in the word 'LangChain'?\n",
      "ü§ñ LLM Response type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "ü§ñ Content: \n",
      "üîß Tool calls: 1\n",
      "   - get_word_length with args: {'word': 'LangChain'}\n",
      "ü§ñ LLM Response type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "ü§ñ Content: \n",
      "üîß Tool calls: 1\n",
      "   - get_word_length with args: {'word': 'LangChain'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize LangChain LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Bind tools to the LLM\n",
    "tools = [calculator_tool, get_word_length]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Simple usage\n",
    "def simple_langchain_tool_call(user_message: str):\n",
    "    print(f\"üë§ User: {user_message}\")\n",
    "    \n",
    "    # Get LLM response\n",
    "    response = llm_with_tools.invoke([HumanMessage(content=user_message)])\n",
    "    \n",
    "    print(f\"ü§ñ LLM Response type: {type(response)}\")\n",
    "    print(f\"ü§ñ Content: {response.content}\")\n",
    "    \n",
    "    # Check for tool calls\n",
    "    if response.tool_calls: # type: ignore\n",
    "        print(f\"üîß Tool calls: {len(response.tool_calls)}\") # type: ignore\n",
    "        for tool_call in response.tool_calls: # type: ignore\n",
    "            print(f\"   - {tool_call['name']} with args: {tool_call['args']}\")\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Test it\n",
    "response1 = simple_langchain_tool_call(\"What is 20 divided by 4?\")\n",
    "print(\"\\n\" + \"-\"*40 + \"\\n\")\n",
    "response2 = simple_langchain_tool_call(\"How many letters are in the word 'LangChain'?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e9ce34",
   "metadata": {},
   "source": [
    "### Step 2.3: Tool Calling Agent with LangChain\n",
    "\n",
    "LangChain provides pre-built agents that automatically handle the tool calling loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "57f84252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Testing: Calculate 15 * 7, then tell me how many letters are in 'calculator'\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `calculator_tool` with `{'operation': 'multiply', 'a': 15, 'b': 7}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m105.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'calculator'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m10\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `calculator_tool` with `{'operation': 'multiply', 'a': 15, 'b': 7}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m105.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'calculator'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m10\u001b[0m\u001b[32;1m\u001b[1;3mThe result of \\( 15 \\times 7 \\) is \\( 105 \\), and the word \"calculator\" has \\( 10 \\) letters.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "‚úÖ Final Answer: The result of \\( 15 \\times 7 \\) is \\( 105 \\), and the word \"calculator\" has \\( 10 \\) letters.\n",
      "\u001b[32;1m\u001b[1;3mThe result of \\( 15 \\times 7 \\) is \\( 105 \\), and the word \"calculator\" has \\( 10 \\) letters.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "‚úÖ Final Answer: The result of \\( 15 \\times 7 \\) is \\( 105 \\), and the word \"calculator\" has \\( 10 \\) letters.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"Calculate 15 * 7, then tell me how many letters are in 'calculator'\",\n",
       " 'output': 'The result of \\\\( 15 \\\\times 7 \\\\) is \\\\( 105 \\\\), and the word \"calculator\" has \\\\( 10 \\\\) letters.'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# Get a prompt template for tool calling agents\n",
    "# Define a prompt template for the tool calling agent\n",
    "\n",
    "# Create a prompt template similar to the one from the hub\n",
    "system_template = \"You are a helpful assistant that can use tools to answer the user's question.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "human_template = \"{input}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        system_message_prompt,\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "        human_message_prompt,\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize prompt with default empty chat history\n",
    "prompt = prompt.partial(chat_history=[])\n",
    "\n",
    "\n",
    "\n",
    "# Create the agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# Create an executor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Test the agent\n",
    "def test_langchain_agent(question: str):\n",
    "    print(f\"\\nüîç Testing: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    result = agent_executor.invoke({\"input\": question})\n",
    "    print(f\"\\n‚úÖ Final Answer: {result['output']}\")\n",
    "    return result\n",
    "\n",
    "# Test with multiple operations\n",
    "test_langchain_agent(\"Calculate 15 * 7, then tell me how many letters are in 'calculator'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54276318",
   "metadata": {},
   "source": [
    "## 3. LangGraph Integration\n",
    "\n",
    "LangGraph allows us to create more complex, stateful workflows with better control over the agent's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "155c40a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from typing import Annotated, Sequence\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba8480c",
   "metadata": {},
   "source": [
    "### Step 3.1: Define State and Create Graph\n",
    "\n",
    "LangGraph uses state management to track conversation and tool usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1a85f200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangGraph workflow created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define our state - LangGraph uses this to track conversation\n",
    "class AgentState(MessagesState):\n",
    "    # MessagesState already includes 'messages' field\n",
    "    # We can add custom fields if needed\n",
    "    pass\n",
    "\n",
    "# Create the tools node\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# Define the agent node\n",
    "def call_model(state: AgentState):\n",
    "    print(f\"ü§ñ Agent thinking... (processing {len(state['messages'])} messages)\")\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Add conditional edges\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    tools_condition,  # This decides whether to call tools or end\n",
    ")\n",
    "\n",
    "# Add edge from tools back to agent\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Add memory for conversation state\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "print(\"‚úÖ LangGraph workflow created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1310320",
   "metadata": {},
   "source": [
    "### Step 3.2: Visualize the Graph (Optional)\n",
    "\n",
    "Let's see what our graph looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "46ecdead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the graph structure\n",
    "try:\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph: {e}\")\n",
    "    print(\"Graph structure:\")\n",
    "    print(app.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee3eca3",
   "metadata": {},
   "source": [
    "### Step 3.3: Run LangGraph Agent\n",
    "\n",
    "Now let's test our LangGraph agent with stateful conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "32ce71c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ User: Calculate 12 * 8\n",
      "--------------------------------------------------\n",
      "ü§ñ Agent thinking... (processing 1 messages)\n",
      "ü§ñ Agent thinking... (processing 3 messages)\n",
      "ü§ñ Agent thinking... (processing 3 messages)\n",
      "ü§ñ Agent: The result of \\( 12 \\times 8 \\) is \\( 96 \\).\n",
      "\n",
      "==================================================\n",
      "\n",
      "üë§ User: Now add 50 to that result\n",
      "--------------------------------------------------\n",
      "ü§ñ Agent thinking... (processing 5 messages)\n",
      "ü§ñ Agent: The result of \\( 12 \\times 8 \\) is \\( 96 \\).\n",
      "\n",
      "==================================================\n",
      "\n",
      "üë§ User: Now add 50 to that result\n",
      "--------------------------------------------------\n",
      "ü§ñ Agent thinking... (processing 5 messages)\n",
      "ü§ñ Agent thinking... (processing 7 messages)\n",
      "ü§ñ Agent thinking... (processing 7 messages)\n",
      "ü§ñ Agent: The result of adding 50 to 96 is \\( 146 \\).\n",
      "\n",
      "==================================================\n",
      "\n",
      "üë§ User: How many characters are in the word 'LangGraph'?\n",
      "--------------------------------------------------\n",
      "ü§ñ Agent thinking... (processing 9 messages)\n",
      "ü§ñ Agent: The result of adding 50 to 96 is \\( 146 \\).\n",
      "\n",
      "==================================================\n",
      "\n",
      "üë§ User: How many characters are in the word 'LangGraph'?\n",
      "--------------------------------------------------\n",
      "ü§ñ Agent thinking... (processing 9 messages)\n",
      "ü§ñ Agent thinking... (processing 11 messages)\n",
      "ü§ñ Agent thinking... (processing 11 messages)\n",
      "ü§ñ Agent: The word \"LangGraph\" has 9 characters.\n",
      "\n",
      "==================================================\n",
      "\n",
      "ü§ñ Agent: The word \"LangGraph\" has 9 characters.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_langgraph_agent(user_input: str, thread_id: str = \"default\"):\n",
    "    print(f\"üë§ User: {user_input}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Configure the thread for conversation memory\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    \n",
    "    # Run the agent\n",
    "    for event in app.stream(\n",
    "        {\"messages\": [HumanMessage(content=user_input)]}, \n",
    "        config=config, # type: ignore\n",
    "        stream_mode=\"values\"\n",
    "    ):\n",
    "        # Print the latest message\n",
    "        if \"messages\" in event and event[\"messages\"]:\n",
    "            latest_message = event[\"messages\"][-1]\n",
    "            if hasattr(latest_message, 'content') and latest_message.content:\n",
    "                if isinstance(latest_message, AIMessage):\n",
    "                    print(f\"ü§ñ Agent: {latest_message.content}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Test the LangGraph agent\n",
    "run_langgraph_agent(\"Calculate 12 * 8\")\n",
    "run_langgraph_agent(\"Now add 50 to that result\", \"default\")  # Uses same thread\n",
    "run_langgraph_agent(\"How many characters are in the word 'LangGraph'?\", \"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cbe031",
   "metadata": {},
   "source": [
    "## 4. ReAct Agent Implementation\n",
    "\n",
    "Now let's implement a full ReAct (Reasoning and Acting) agent that shows its thinking process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e818fd7c",
   "metadata": {},
   "source": [
    "### Step 4.1: Enhanced Tools for ReAct\n",
    "\n",
    "Let's add more tools to make our ReAct agent more interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ae91cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created 5 tools for ReAct agent:\n",
      "  - calculator_tool: Perform basic arithmetic operations (add, subtract, multiply, divide)\n",
      "  - get_word_length: Get the length of a word\n",
      "  - get_current_time: Get the current date and time\n",
      "  - generate_random_number: Generate a random number within a specified range\n",
      "  - text_analyzer: Analyze text and return various statistics\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import random\n",
    "\n",
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get the current date and time.\n",
    "    \n",
    "    Returns:\n",
    "        Current date and time as a string\n",
    "    \"\"\"\n",
    "    return datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "@tool\n",
    "def text_analyzer(text: str) -> dict:\n",
    "    \"\"\"Analyze text and return various statistics.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to analyze\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with text statistics\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    sentences = text.split('.') if '.' in text else [text]\n",
    "    \n",
    "    return {\n",
    "        \"character_count\": len(text),\n",
    "        \"word_count\": len(words),\n",
    "        \"sentence_count\": len([s for s in sentences if s.strip()]),\n",
    "        \"average_word_length\": sum(len(word) for word in words) / len(words) if words else 0\n",
    "    }\n",
    "\n",
    "@tool\n",
    "def generate_random_number(min_value: int = 1, max_value: int = 100) -> int:\n",
    "    \"\"\"Generate a random number between min_value and max_value.\n",
    "    \n",
    "    Args:\n",
    "        min_value: Minimum value (inclusive)\n",
    "        max_value: Maximum value (inclusive)\n",
    "    \"\"\"\n",
    "    return random.randint(min_value, max_value)\n",
    "\n",
    "# Updated tools list\n",
    "react_tools = [\n",
    "    calculator_tool,\n",
    "    get_word_length,\n",
    "    get_current_time,\n",
    "    generate_random_number,\n",
    "    text_analyzer\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Created {len(react_tools)} tools for ReAct agent:\")\n",
    "for tool in react_tools:\n",
    "    print(f\"  - {tool.name}: {tool.description.split('.')[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be63ed5",
   "metadata": {},
   "source": [
    "### Step 4.2: Custom ReAct Prompt\n",
    "\n",
    "The key to ReAct is the prompt that encourages reasoning and action steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "26820dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ReAct prompt template created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Custom ReAct prompt template\n",
    "react_prompt = \"\"\"\n",
    "You are a helpful assistant that can reason about problems and use tools to solve them.\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚úÖ ReAct prompt template created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a069ea",
   "metadata": {},
   "source": [
    "### Step 4.3: ReAct Agent with LangGraph\n",
    "\n",
    "Let's implement a ReAct agent using LangGraph that shows clear reasoning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89631079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Question: I need you to:\n",
      "1. Generate a random number between 10 and 50\n",
      "2. Multiply that number by 3\n",
      "3. Tell me what time it is\n",
      "4. Analyze the text \"The quick brown fox jumps over the lazy dog\"\n",
      "\n",
      "üìù ReAct Agent Reasoning Process:\n",
      "============================================================\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 363, 'total_tokens': 371, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-Bx3xIyfwWnr1Us7DHPgcrfy4YOD5X', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--e212c491-65a0-4231-b9ee-1cde70a66d3b-0', usage_metadata={'input_tokens': 363, 'output_tokens': 8, 'total_tokens': 371, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Create ReAct prompt\n",
    "\n",
    "\n",
    "# Create ReAct agent using LangGraph's implementation\n",
    "react_agent = create_react_agent(model=llm, tools=react_tools, prompt=react_prompt, version=\"v2\")\n",
    "\n",
    "# Function to run the ReAct agent\n",
    "def run_react_agent(question: str):\n",
    "    print(f\"üéØ Question: {question}\")\n",
    "    print(\"\\nüìù ReAct Agent Reasoning Process:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Stream the agent's thinking process to see step-by-step reasoning\n",
    "    for chunk in react_agent.stream({\"input\": question}):\n",
    "        if \"actions\" in chunk:\n",
    "            for action in chunk[\"actions\"]:\n",
    "                print(f\"üß† Thought: {action.log}\")\n",
    "                print(f\"üîß Action: {action.tool}\")\n",
    "                print(f\"üì• Input: {action.tool_input}\")\n",
    "                print(\"-\" * 40)\n",
    "        elif \"output\" in chunk:\n",
    "            print(f\"\\nüéâ Final Answer: {chunk['output']}\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Return the final result\n",
    "    result = react_agent.invoke({\"input\": question})\n",
    "    return result\n",
    "\n",
    "# Test with a complex multi-step problem\n",
    "complex_question = \"\"\"\n",
    "I need you to:\n",
    "1. Generate a random number between 10 and 50\n",
    "2. Multiply that number by 3\n",
    "3. Tell me what time it is\n",
    "4. Analyze the text \"The quick brown fox jumps over the lazy dog\"\n",
    "\"\"\"\n",
    "\n",
    "run_react_agent(complex_question.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e3f68a",
   "metadata": {},
   "source": [
    "## üèÅ Conclusion\n",
    "\n",
    "Congratulations! You've learned how to:\n",
    "\n",
    "1. **Understand tool calling fundamentals** - How LLMs decide when and how to use tools\n",
    "2. **Implement basic tool calling** - Direct OpenAI API usage with manual handling\n",
    "3. **Use LangChain for simplification** - Leverage frameworks for easier development\n",
    "4. **Build complex workflows with LangGraph** - State management and visual workflows\n",
    "5. **Create ReAct agents** - Reasoning and acting patterns for better problem-solving\n",
    "\n",
    "### Next Steps:\n",
    "- Try creating more complex tools (web search, file operations, API calls)\n",
    "- Experiment with different prompting strategies\n",
    "- Build domain-specific agents for your use cases\n",
    "- Explore error handling and tool validation\n",
    "- Look into tool composition and chaining\n",
    "\n",
    "Happy building! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
